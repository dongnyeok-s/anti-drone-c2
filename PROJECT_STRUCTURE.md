# í”„ë¡œì íŠ¸ êµ¬ì¡° ê°€ì´ë“œ

## ğŸ“ ì „ì²´ êµ¬ì¡°

```
ë“œë¡ ì§€íœ˜í†µì œì²´ê³„/
â”œâ”€â”€ simulator/          # ì‹œë®¬ë ˆì´í„° ì„œë²„ (TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.ts                    # ì§„ì…ì 
â”‚   â”‚   â”œâ”€â”€ simulation.ts               # ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„
â”‚   â”‚   â”œâ”€â”€ websocket/server.ts         # WebSocket ì„œë²„
â”‚   â”‚   â”œâ”€â”€ core/                       # í•µì‹¬ ë¡œì§
â”‚   â”‚   â”‚   â”œâ”€â”€ fusion/                 # ì„¼ì„œ ìœµí•©
â”‚   â”‚   â”‚   â”œâ”€â”€ engagement/             # êµì „ ê´€ë¦¬
â”‚   â”‚   â”‚   â”œâ”€â”€ scenario/               # ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
â”‚   â”‚   â”‚   â””â”€â”€ logging/                # ë¡œê¹… ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ models/                     # ë“œë¡ /ìš”ê²©ê¸° ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ sensors/                    # ì„¼ì„œ êµ¬í˜„
â”‚   â”‚   â”œâ”€â”€ evaluation/                 # í‰ê°€ ì„¤ì •
â”‚   â”‚   â””â”€â”€ scripts/                    # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ runtime_params.json         # ëŸ°íƒ€ì„ íŒŒë¼ë¯¸í„°
â”‚
â”œâ”€â”€ frontend/           # C2 UI (React + TypeScript)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/                 # UI ì»´í¬ë„ŒíŠ¸
â”‚       â”œâ”€â”€ hooks/                      # React Hooks
â”‚       â””â”€â”€ logic/                      # í”„ë¡ íŠ¸ì—”ë“œ ë¡œì§
â”‚
â”œâ”€â”€ analysis/           # ë¶„ì„ ë° í‰ê°€ (Python)
â”‚   â”œâ”€â”€ scripts/                        # ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”‚   â”œâ”€â”€ eval_classification_report.py
â”‚   â”‚   â”œâ”€â”€ run_full_evaluation.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ plots/                          # ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ results/                        # ê²°ê³¼ íŒŒì¼
â”‚   â””â”€â”€ create_reports.py               # ë¦¬í¬íŠ¸ ìƒì„±
â”‚
â”œâ”€â”€ shared/             # ê³µìœ  íƒ€ì… ì •ì˜ (TypeScript)
â”‚   â””â”€â”€ schemas.ts
â”‚
â”œâ”€â”€ audio_model/        # ì˜¤ë””ì˜¤ ëª¨ë¸ (Python)
â””â”€â”€ backend/           # ë°±ì—”ë“œ (í˜„ì¬ ë¹„ì–´ìˆìŒ)
```

## ğŸ”„ ì£¼ìš” ì›Œí¬í”Œë¡œìš°

### 1. ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
```
simulator/src/index.ts
  â†’ SimulatorWebSocketServer
    â†’ SimulationEngine
      â†’ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± â†’ ì„¼ì„œ ìœµí•© â†’ ìœ„í˜‘ í‰ê°€ â†’ êµì „
```

### 2. í‰ê°€ íŒŒì´í”„ë¼ì¸
```
analysis/scripts/run_full_evaluation.py
  â†’ simulator/src/scripts/run_evaluation_experiments.ts
    â†’ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ (NíšŒ ë°˜ë³µ)
      â†’ JSONL ë¡œê·¸ ìƒì„±
        â†’ analysis/scripts/eval_classification_report.py
          â†’ metrics.json ìƒì„±
            â†’ analysis/create_reports.py
              â†’ ë¦¬í¬íŠ¸ ìƒì„±
```

### 3. ìë™ íŠœë‹
```
analysis/auto_tune.py
  â†’ íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
    â†’ runtime_params.json ìƒì„±
      â†’ í‰ê°€ ì‹¤í–‰
        â†’ objective score ê³„ì‚°
          â†’ best_config ì €ì¥
```

## ğŸ“ ì£¼ìš” ì„¤ì • íŒŒì¼

1. **ì‹œë®¬ë ˆì´í„° ì„¤ì •**
   - `simulator/src/config.ts` - ê¸°ë³¸ ì„¤ì •
   - `simulator/config/runtime_params.json` - ëŸ°íƒ€ì„ íŒŒë¼ë¯¸í„° (íŠœë‹ ê²°ê³¼)

2. **í‰ê°€ ì„¤ì •**
   - `simulator/src/evaluation/config.ts` - í‰ê°€ ì‹¤í—˜ ì„¤ì •

3. **ë¶„ì„ ì„¤ì •**
   - `analysis/auto_tuning_config.py` - íŠœë‹ íŒŒë¼ë¯¸í„° ë²”ìœ„

## ğŸ¯ ì£¼ìš” ì§„ì…ì 

### ì‹œë®¬ë ˆì´í„°
```bash
cd simulator
npm run dev          # ê°œë°œ ëª¨ë“œ
npm run eval         # í‰ê°€ ì‹¤í–‰
npm run eval:full    # Full í‰ê°€
```

### ë¶„ì„
```bash
cd analysis
python scripts/run_full_evaluation.py    # Full í‰ê°€
python create_reports.py                  # ë¦¬í¬íŠ¸ ìƒì„±
python auto_tune.py --trials 20           # ìë™ íŠœë‹
```

## âš ï¸ ë³µì¡ë„ ì´ìŠˆ

### í˜„ì¬ ë¬¸ì œì 
1. **ìŠ¤í¬ë¦½íŠ¸ ë¶„ì‚°**: í‰ê°€ ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ê°€ ì—¬ëŸ¬ ê³³ì— ë¶„ì‚°
   - `simulator/src/scripts/`
   - `analysis/scripts/`
   - `analysis/plots/`

2. **ì„¤ì • íŒŒì¼ ì¤‘ë³µ**: ì—¬ëŸ¬ ê³³ì— ì„¤ì •ì´ ë¶„ì‚°
   - `simulator/src/config.ts`
   - `simulator/src/evaluation/config.ts`
   - `simulator/config/runtime_params.json`
   - `analysis/auto_tuning_config.py`

3. **ë¡œê·¸ ê²½ë¡œ ë³µì¡**: ë¡œê·¸ê°€ ì—¬ëŸ¬ ë””ë ‰í† ë¦¬ì— ì €ì¥
   - `simulator/logs/`
   - `simulator/logs/eval/`
   - `simulator/logs/eval_full/`
   - `simulator/logs/eval_comparison/`

### ê°œì„  ì œì•ˆ
1. **ìŠ¤í¬ë¦½íŠ¸ í†µí•©**: í‰ê°€ ê´€ë ¨ ìŠ¤í¬ë¦½íŠ¸ë¥¼ `analysis/scripts/`ë¡œ í†µí•©
2. **ì„¤ì • ì¤‘ì•™í™”**: ëª¨ë“  ì„¤ì •ì„ `config/` ë””ë ‰í† ë¦¬ë¡œ í†µí•©
3. **ë¡œê·¸ êµ¬ì¡° ë‹¨ìˆœí™”**: ë‹¨ì¼ ë¡œê·¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¡œ ì •ë¦¬

## ğŸ“š ì‚¬ìš© ê°€ì´ë“œ

### ê¸°ë³¸ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
```bash
cd simulator
npm run dev
```

### í‰ê°€ ì‹¤í–‰
```bash
# Fast ëª¨ë“œ
cd simulator
npm run eval:fast

# Full ëª¨ë“œ
npm run eval:full
```

### ë¦¬í¬íŠ¸ ìƒì„±
```bash
cd analysis
python create_reports.py
```

### ìë™ íŠœë‹
```bash
cd analysis
python auto_tune.py --trials 20 --profile fast
```

